How to implement a new network model in TF2?
This instruction aims to give the beginners a brief guide on how to implement a new network model in TF2. If you want more details on specific procedures, please refer to Readme files locating in corresponding file folders:
1. Model Compression: Use run.sh in https://github.com/TF2-Engine/TF2/tree/master/TransForm_Kit/Compression/compress_net to get the compressed model ( for example, /models/part5_model_best.pth.tar mentioned in the Readme file ). If the model needs to be modified, please refer to the code commenting in run.sh and model names defined in torchvision ( https://github.com/pytorch/vision/tree/master/torchvision ).
2. Model Conversion: Use the tools in https://github.com/TF2-Engine/TF2/tree/master/TransForm_Kit/ModelConvert to convert the compressed model generated in Step 1 to fpganetwork.bin and fpgamodel.bin.
3. Generating Header File: Use the tools in https://github.com/TF2-Engine/TF2/tree/master/Runtime_Engine/TF2_auto_config to generate corresponding network.h file from fpganetwork.bin generated in Step 2.
4. Quantization: 
  (1) Download Model file: For instance, squeezenet.py can be downloaded from https://github.com/pytorch/vision/blob/master/torchvision/models/squeezenet.py as the model file. Move it into TransForm_Kit/Quantization/models.
  (2) Load Model: Copy the compressed model referred in Step 1 ( for example, /models/part5_model_best.pth.tar ) to TransForm_Kit/Quantization/weights. Load the compressed model using TransForm_Kit/Quantization/load_mode.py.
  (3) Feature Map Quantization: Follow the steps described in Readme file in https://github.com/TF2-Engine/TF2/tree/master/TransForm_Kit/Quantization to quantize the feature map and generate the q files for TF2 Runtime_Engine. Combine the q files into one based on the q file reading order coded in Runtime_Engine/cnn/host/src/quantization.cpp
5. Compilation and Emulation: Compile and run the device and host code for emulation according to the OpenCL Programming Guide for corresponding FPGA chip to emulate and debug the functionality. Please refer to Runtime_Engine/cnn/recompile.sh, Runtime_Engine/cnn/device/emu.sh and Runtime_Engine/cnn/run.sh as an example for F10A card.
6. Hardware Compilation: Compile the device code without building hardware ( If the FPGA chip supports this feature ) to acquire the pipeline status, resource usage and other information about the hardware compilation and optimize the device code based on this information. Compile the device code to build the hardware and run the whole program to evaluate the final performance. Please refer to Runtime_Engine/cnn/device/full_compile.sh and Runtime_Engine/cnn/run.sh as an example for F10A card.